"""Fitting with Deep Learning."""

import logging
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import torch
from hydra.utils import instantiate
from hydra_plugins.hydra_submitit_launcher.config import (
    LocalQueueConf,
    SlurmQueueConf,
)
from hydra_plugins.hydra_submitit_launcher.submitit_launcher import (
    SlurmLauncher,
)
from lightning.pytorch import Trainer
from lightning.pytorch.loggers import Logger
from lightning.pytorch.loggers.wandb import WandbLogger
from omegaconf import MISSING
from torch.distributed import ReduceOp

from cneuromax.fitting import BaseFittingHydraConfig
from cneuromax.fitting.deeplearning.datamodule import BaseDataModule
from cneuromax.fitting.deeplearning.litmodule import BaseLitModule
from cneuromax.fitting.deeplearning.utils.lightning import (
    InitOptimParamsCheckpointConnector,
    find_good_num_workers,
    find_good_per_device_batch_size,
)
from cneuromax.utils.hydra import get_launcher_config, get_path

TORCH_COMPILE_MINIMUM_CUDA_VERSION = 7


@dataclass
class DeepLearningFittingHydraConfig(BaseFittingHydraConfig):
    """Structured :mod:`hydra-core` config for Deep Learning fitting.

    Attributes:
        trainer: Implicit (generated by :mod:`hydra-zen`)\
            `TrainerHydraConfig` instance that would have wrapped\
            :class:`lightning.pytorch.Trainer`.
        litmodule: Implicit (generated by :mod:`hydra-zen`)\
            `LitModuleHydraConfig` instance that would have wrapped\
            :class:`cneuromax.fitting.deeplearning.litmodule.BaseLitModule`.
        datamodule: Implicit (generated by :mod:`hydra-zen`)\
            `DataModuleHydraConfig` instance that would have wrapped\
            :class:`cneuromax.fitting.deeplearning.datamodule.BaseDataModule`.
        logger: Implicit (generated by :mod:`hydra-zen`)\
            `LoggerHydraConfig` instance that would have wrapped\
            :class:`lightning.pytorch.loggers.Logger`.
    """

    trainer: Any = MISSING
    litmodule: Any = MISSING
    datamodule: Any = MISSING
    logger: Any = MISSING


def fit(config: DeepLearningFittingHydraConfig) -> float:
    """Trains a Deep Learning model.

    This function is the main entry point of the Deep Learning module.
    It acts as an interface between :mod:`hydra-core` (configuration +
    launcher + sweeper) and :mod:`lightning` (trainer + logger +
    modules).

    Note that this function will be executed by
    `num_nodes * gpus_per_node` processes/tasks. Those variables are
    set in the Hydra launcher configuration.

    Trains (or resumes training) the model, saves a checkpoint and
    returns the final validation loss.

    Args:
        config: The fitting configuration, see
            :class:`DeepLearningFittingHydraConfig`.

    Returns:
        The final validation loss.
    """
    launcher_config = get_launcher_config()
    logger, trainer, datamodule, litmodule = instantiate_lightning_objects(
        config,
        launcher_config,
    )
    set_batch_size_and_num_workers(
        config,
        trainer,
        datamodule,
    )
    ckpt_path = set_checkpoint_path(config, trainer)
    trainer.fit(model=litmodule, datamodule=datamodule, ckpt_path=ckpt_path)
    if config.model_load_path:
        trainer.save_checkpoint(config.model_load_path)
    return trainer.validate(model=litmodule, datamodule=datamodule)[0][
        "val/loss"
    ]


def instantiate_lightning_objects(
    config: DeepLearningFittingHydraConfig,
    launcher_config: LocalQueueConf | SlurmQueueConf,
) -> tuple[Logger | None, Trainer, BaseDataModule, BaseLitModule]:
    """Creates several :mod:`lightning` objects based on the config.

    Args:
        config: See :class:`DeepLearningFittingHydraConfig`.
        launcher_config: The Hydra launcher configuration.

    Returns:
        The instantiated :mod:`lightning` objects.
    """
    logger: Logger | None
    if config.logger._target_ == get_path(WandbLogger):  # noqa: SLF001
        wandb_key_path = Path(
            str(os.environ.get("CNEUROMAX_PATH")) + "/WANDB_KEY.txt",
        )
        if wandb_key_path.exists():
            kwargs = {}
            if launcher_config._target_ == get_path(  # noqa: SLF001
                SlurmLauncher,
            ):
                kwargs["offline"] = True
            logger = instantiate(config.logger, **kwargs)
        else:
            logging.info("W&B key not found. Logging disabled.")
            logger = None
    else:
        logger = instantiate(config.logger)

    callbacks = None
    """
    # noqa: SLF001
    if launcher_config._target_ == get_path(SlurmLauncher):
        callbacks = [TriggerWandbSyncLightningCallback()]
    """
    trainer: Trainer = instantiate(
        config=config.trainer,
        devices=launcher_config.gpus_per_node or 1
        if config.device == "gpu"
        else launcher_config.tasks_per_node,
        logger=logger,
        callbacks=callbacks,
    )

    datamodule: BaseDataModule = instantiate(config.datamodule)

    litmodule: BaseLitModule = instantiate(config.litmodule)
    if (
        config.device == "gpu"
        and torch.cuda.get_device_capability()[0]
        >= TORCH_COMPILE_MINIMUM_CUDA_VERSION
    ):
        # mypy: torch.compile not typed for Lightning.
        litmodule = torch.compile(litmodule)  # type: ignore [assignment]

    return logger, trainer, datamodule, litmodule


def set_batch_size_and_num_workers(
    config: DeepLearningFittingHydraConfig,
    trainer: Trainer,
    datamodule: BaseDataModule,
) -> None:
    """Computes and sets the batch size and number of workers.

    If starting a new HPO run, finds and sets "good" `batch_size` and
    `num_workers` parameters.

    See the
    :func:`cneuromax.fitting.deeplearning.utils.lightning.find_good_batch_size`
    and
    :func:`cneuromax.fitting.deeplearning.utils.lightning.find_good_num_workers`
    functions documentation for more details.

    We make the assumption that if we are resuming from a checkpoint
    created while running hyper-parameter optimization, we are running
    on the same hardware configuration as was used to create the
    checkpoint. Therefore, we do not need to once again look for good
    `batch_size` and `num_workers` parameters.

    Args:
        config: .
        trainer: .
        datamodule: .
    """
    if not config.pbt_load_path:
        proposed_per_device_batch_size: int = find_good_per_device_batch_size(
            instantiate(config.litmodule),
            instantiate(config.datamodule),
            config.device,
            config.data_dir,
        )
        proposed_per_device_num_workers: int = find_good_num_workers(
            config.datamodule,
            proposed_per_device_batch_size,
        )

    per_device_batch_size: int = int(
        trainer.strategy.reduce(
            torch.tensor(proposed_per_device_batch_size),
            reduce_op=ReduceOp.MIN,  # type: ignore [arg-type]
        ),
    )

    per_device_num_workers: int = int(
        trainer.strategy.reduce(
            torch.tensor(proposed_per_device_num_workers),
            reduce_op=ReduceOp.MAX,  # type: ignore [arg-type]
        ),
    )

    datamodule.per_device_batch_size = per_device_batch_size
    datamodule.per_device_num_workers = per_device_num_workers


def set_checkpoint_path(
    config: DeepLearningFittingHydraConfig,
    trainer: Trainer,
) -> str | None:
    """Sets the path to the checkpoint to resume training from.

    Three cases are considered:
    - if the :paramref:`DeepLearningFittingHydraConfig.load_path_pbt`
    parameter is set, we are resuming from a checkpoint created while
    running HPO. In this case, we set the checkpoint path to the value
    of :paramref:`DeepLearningFittingHydraConfig.load_path_hpo` and
    use a custom checkpoint connector to not override the new HPO
    config values.
    - if the :paramref:`DeepLearningFittingHydraConfig.load_path`
    parameter is set (but not
    :paramref:`DeepLearningFittingHydraConfig.load_path_hpo`), we are
    resuming from a regular checkpoint. In this case, we set the
    checkpoint path to the value of
    :paramref:`DeepLearningFittingHydraConfig.load_path`.
    - if neither
    :paramref:`DeepLearningFittingHydraConfig.load_path_hpo` nor
    :paramref:`DeepLearningFittingHydraConfig.load_path` are set, we
    are starting a new training run. In this case, we set the
    checkpoint path to `None`.

    Args:
        config: The config instance used for this fitting run.
        trainer: The :class:`lightning.pytorch.Trainer` instance used
            for this fitting run.

    Returns:
        The path to the checkpoint to resume training from.
    """
    ckpt_path: str | None

    if config.pbt_load_path:
        ckpt_path = config.pbt_load_path
        # No choice but to access a private attribute.
        trainer._checkpoint_connector = (  # noqa: SLF001
            InitOptimParamsCheckpointConnector(
                trainer,
            )
        )
    elif config.model_load_path:
        ckpt_path = config.model_load_path
    else:
        ckpt_path = None

    return ckpt_path
